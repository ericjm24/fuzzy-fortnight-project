{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dict = {\n",
    "    \"DP05_0001E\":\"total_population\",\n",
    "    \"DP05_0032E\":\"white_population\",\n",
    "    \"DP05_0066E\":\"hispanic_population\",\n",
    "    \"DP02_0092E\":\"foreign_born_population\",\n",
    "    \"DP05_0017E\":\"median_age\",\n",
    "    \"DP03_0062E\":\"median_household_income\",\n",
    "    \"DP03_0063E\":\"mean_household_income\",\n",
    "    \"DP03_0128PE\":\"poverty_population\",\n",
    "    \"DP04_0001E\":\"total_housing_units\",\n",
    "    \"DP04_0126E\":\"units_paying_rent\",\n",
    "    \"DP03_0005E\":\"unemployed_population\",\n",
    "    \"DP03_0032E\":\"working\",\n",
    "    \"DP03_0033E\":\"agriculture_industry\",\n",
    "    \"DP03_0039E\":\"information_industry\",\n",
    "    \"DP03_0035E\":\"manufacturing_industry\",\n",
    "    \"DP03_0040E\":\"financial_industry\",\n",
    "    \"DP03_0043E\":\"entertainment_industry\",\n",
    "    \"DP03_0048E\":\"government_employee\",\n",
    "    \"DP02_0063E\":\"degree_associate\",\n",
    "    \"DP02_0064E\":\"degree_bachelor\",\n",
    "    \"DP02_0065E\":\"degree_higher\",\n",
    "    \"DP02_0068E\":\"veteran_population\",\n",
    "    \"DP03_0006E\":\"armed_forces_population\",\n",
    "    \"DP03_0099E\":\"no_insurance\",\n",
    "    \"DP03_0098E\":\"public_insurance\",\n",
    "    \"DP03_0095E\":\"non_institutionalized_population\"\n",
    "    }\n",
    "arc_name = \"data/stream/2015/04/07\"\n",
    "save_name = \"data/twitter_dump.txt\"\n",
    "\n",
    "import geonamescache\n",
    "gc = geonamescache.GeonamesCache()\n",
    "internat_cities = [c for c in gc.get_cities().values() if c['population'] >= 100000 and c['countrycode'] != 'US']\n",
    "for c in internat_cities:\n",
    "    c['state'] = 'INTERNATIONAL'\n",
    "import pycountry\n",
    "countries = [c.name.title() for c in pycountry.countries]\n",
    "planets = ['Mercury', 'Venus', 'Earth', 'Mars', 'Moon', 'Jupiter', 'Saturn', 'Uranus', 'Neptune', 'Pluto'] #Pluto is not a planet\n",
    "import requests\n",
    "from config import census_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cit_file = \"data/uscities.csv\"\n",
    "cities = []\n",
    "with open(cit_file, \"r\") as f:\n",
    "    k = 0\n",
    "    for line in f:\n",
    "        if k == 0:\n",
    "            k=1\n",
    "            continue\n",
    "        \n",
    "        row = [x.replace('\\\"', '') for x in line.split(',')]\n",
    "        try:\n",
    "            temp = {\n",
    "                'name':row[0],\n",
    "                'state':row[2],\n",
    "                'longitude':float(row[8]),\n",
    "                'latitude':float(row[9]),\n",
    "                'population':int(round(float(row[10]))),\n",
    "                'density':float(row[11])\n",
    "            }\n",
    "            cities.append(temp)\n",
    "        except:\n",
    "            temp = {\n",
    "                'name':', '.join(row[0:2]),\n",
    "                'state':row[4],\n",
    "                'longitude':row[10],\n",
    "                'latitude':row[11],\n",
    "                'population':int(round(float(row[12]))),\n",
    "                'density':float(row[13])\n",
    "            }\n",
    "            cities.append(temp)\n",
    "city_names = {}\n",
    "for c in cities:\n",
    "    if c['name'] in city_names.keys():\n",
    "        city_names[c['name']][c['state']] = c\n",
    "    else:\n",
    "        city_names[c['name']] = {c['state']:c}\n",
    "for c in internat_cities:\n",
    "    if c['name'] in city_names.keys():\n",
    "        city_names[c['name']]['state'] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbr_to_states = {\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'DC': 'District of Columbia',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VI': 'Virgin Islands',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming'\n",
    "}\n",
    "\n",
    "state_to_abbr = {v.upper():k for k,v in abbr_to_states.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wash_dc = city_names['Washington']['DC']\n",
    "nyc = city_names['New York']['NY']\n",
    "\n",
    "def match_country(st):\n",
    "    if st.lower() in ['us', 'usa', 'america', 'united states', 'united states of america', 'amerika', 'murica', \"'murica\"]:\n",
    "        return 'USA'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def match_state(st):\n",
    "    stat = st.upper()\n",
    "    if 'USA' in stat:\n",
    "        stat = stat.replace('USA', '').strip()\n",
    "    if 'AMERICA' in stat:\n",
    "        stat = stat.replace('AMERICA', '').strip()\n",
    "    if 'US' in stat:\n",
    "        stat = stat.replace('US', '').strip()\n",
    "    if stat in state_to_abbr.keys():\n",
    "        return state_to_abbr[stat]\n",
    "    elif stat not in state_to_abbr.values():\n",
    "        return None\n",
    "    return stat\n",
    "\n",
    "def match_city(cit, st = None):\n",
    "    city = cit.title()\n",
    "    if city in ['Nederland', 'Russia', 'Scotland', 'Wales', 'England', 'Nowhere', 'Uncertain']:\n",
    "        return None\n",
    "    if city == 'New York City' or cit == 'Nyc':\n",
    "        return nyc\n",
    "    if st is None:\n",
    "        if city in countries or city in planets:\n",
    "            return None\n",
    "        out = city_names.get(city, None)\n",
    "        if out and len(out.keys()) > 1:\n",
    "            temp = 0\n",
    "            for c in out.values():\n",
    "                if c['population']>temp:\n",
    "                    temp = c['population']\n",
    "                    oout = c\n",
    "            if oout['state'] != 'INTERNATIONAL' and oout['population'] >= 10000:\n",
    "                return oout\n",
    "            else:\n",
    "                return None\n",
    "        elif out and len(out.keys())==1:\n",
    "            return list(out.values())[0]\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        #print(cit, st)\n",
    "        if st == 'DC':\n",
    "            return wash_dc\n",
    "        out = city_names.get(cit, None)\n",
    "        if out:\n",
    "            out = out.get(st, None)\n",
    "            if out:\n",
    "                return out\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "def match_string(st):\n",
    "    st = st.strip()\n",
    "    st = st.replace('.', '')\n",
    "    if st.lower() == 'la':\n",
    "        return match_string('Los Angeles, CA')\n",
    "    if st.lower() == 'sf':\n",
    "        return match_string('San Francisco, CA')\n",
    "    if st.lower() == 'nyc':\n",
    "        return nyc\n",
    "    if 'nova iorque' in st.lower():\n",
    "        return nyc\n",
    "    if 'washington' in st.lower() and 'dc' in st.lower().replace('.',''):\n",
    "        return wash_dc\n",
    "    if st.count(',') == 0:\n",
    "        try:\n",
    "            out = match_country(st)\n",
    "            if out:\n",
    "                return out\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            out = match_state(st)\n",
    "            if out:\n",
    "                return out\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            out = match_city(st)\n",
    "            if out:\n",
    "                return out\n",
    "        except:\n",
    "            pass\n",
    "        if st.count(' ') > 0:\n",
    "            temp = st.split(' ')\n",
    "            if len(temp) == 2:\n",
    "                return match_string(', '.join(temp))\n",
    "            else:\n",
    "                return match_string(' '.join(temp[0:-1]) + ', ' + temp[-1])\n",
    "        return None\n",
    "    elif st.count(',') == 1:\n",
    "        cit, st = st.split(',')\n",
    "        cit = cit.strip().title()\n",
    "        st = st.strip().upper()\n",
    "        if match_country(st):\n",
    "            if match_state(cit.upper()):\n",
    "                return match_state(cit.upper())\n",
    "            elif match_city(cit):\n",
    "                return match_city(cit)\n",
    "            else:\n",
    "                return 'USA'\n",
    "        elif match_state(st):\n",
    "            st = match_state(st)\n",
    "            if match_city(cit,st):\n",
    "                return match_city(cit,st)\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "        else:\n",
    "            return None\n",
    "    elif st.count(',') == 2:\n",
    "        cit, st, ct = st.split(',')\n",
    "        if match_country(ct.strip()):\n",
    "            return match_string(','.join([cit,st]))\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "200\n"
    }
   ],
   "source": [
    "def parse_census_city(city_name):\n",
    "    city, state = city_name.split(', ')\n",
    "    city = ' '.join(city.split(' ')[:-1])\n",
    "    state = state_to_abbr.get(state.upper(), None)\n",
    "    return city, state\n",
    "\n",
    "stats_name_map = {v:k for k,v in stats_dict.items()}\n",
    "url = \"https://api.census.gov/data/2017/acs/acs5/profile?get=\"\n",
    "url += \",\".join(stats_dict.keys())\n",
    "url += \",NAME&for=place:*&in=state:*\"\n",
    "url += '&key=' + census_key\n",
    "response = requests.get(url)\n",
    "print(response.status_code)\n",
    "if response.status_code < 400:\n",
    "    data = response.json()\n",
    "    my_data = data\n",
    "    ind = data[0].index(\"NAME\")\n",
    "    stats_ind = {s:data[0].index(s) for s in stats_dict.keys()}\n",
    "    for data_point in data[1:]:\n",
    "        try:\n",
    "            city, state = parse_census_city(data_point[ind])\n",
    "        except:\n",
    "            print(data_point[ind])\n",
    "            continue\n",
    "        if state and match_city(city, state):\n",
    "            for k,v in stats_ind.items():\n",
    "                city_names[city][state][stats_dict[k]] = data_point[v]\n",
    "\n",
    "url = url = \"https://api.census.gov/data/2017/acs/acs5/profile?get=\"\n",
    "url += \",\".join(stats_dict.keys())\n",
    "url += \",NAME&for=state:*\"\n",
    "url += '&key=' + census_key\n",
    "state_stats = {}\n",
    "response = requests.get(url)\n",
    "if response.status_code < 400:\n",
    "    data = response.json()\n",
    "    ind = data[0].index(\"NAME\")\n",
    "    stats_ind = {s:data[0].index(s) for s in stats_dict.keys()}\n",
    "    for data_point in data[1:]:\n",
    "        if not state_to_abbr.get(data_point[ind].upper(), False):\n",
    "            continue\n",
    "        state = state_to_abbr[data_point[ind].upper()]\n",
    "        state_stats[state] = {}\n",
    "        for k,v in stats_ind.items():\n",
    "            state_stats[state][stats_dict[k]] = data_point[v]\n",
    "\n",
    "url = url = \"https://api.census.gov/data/2017/acs/acs5/profile?get=\"\n",
    "url += \",\".join(stats_dict.keys())\n",
    "url += \",NAME&for=us:*\"\n",
    "url += '&key=' + census_key\n",
    "response = requests.get(url)\n",
    "if response.status_code < 400:\n",
    "    data = response.json()\n",
    "    ind = data[0].index(\"NAME\")\n",
    "    stats_ind = {s:data[0].index(s) for s in stats_dict.keys()}\n",
    "    state_stats['USA'] = {}\n",
    "    for k,v in stats_ind.items():\n",
    "        state_stats['USA'][stats_dict[k]] = data_point[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_list = list(stats_dict.values())\n",
    "def get_user_data(tweet):\n",
    "    if (not tweet) or (not tweet.get('user', None)) or (not tweet['user']['location']):\n",
    "        return None\n",
    "    loc = match_string(tweet['user']['location'])\n",
    "    if loc:\n",
    "        if type(loc)==dict:\n",
    "            out = [\n",
    "                tweet['user']['id_str'],\n",
    "                tweet['user']['friends_count'],\n",
    "                tweet['user']['followers_count'],\n",
    "                loc['state'],\n",
    "                loc['name'],\n",
    "                loc['latitude'],\n",
    "                loc['longitude'],\n",
    "                tweet['user']['created_at'],\n",
    "                loc['density']\n",
    "            ]\n",
    "            for s in stats_list:\n",
    "                out.append(loc.get(s, None))\n",
    "        else:\n",
    "            out = [\n",
    "                tweet['user']['id_str'],\n",
    "                tweet['user']['friends_count'],\n",
    "                tweet['user']['followers_count'],\n",
    "                loc,\n",
    "                None,\n",
    "                None,\n",
    "                None,\n",
    "                tweet['user']['created_at'],\n",
    "                None\n",
    "            ]\n",
    "            for s in stats_list:\n",
    "                out.append(state_stats.get(loc, {}).get(s, None))\n",
    "        return out\n",
    "    else:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twitterArchiveParser import twitterArchiveParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = twitterArchiveParser(archive_location=arc_name, save_location = save_name, num_threads = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Thread finished\n\nThread finished\n\nThread finished\n\nThread finished\n\nThread finished\n\nThread finished\n\nThread finished\n\n"
    }
   ],
   "source": [
    "header_string = 'id,friends,followers,state,city,latitude,longitude,created_at,density,' + ','.join(stats_list)\n",
    "tp.write_header(header_string)\n",
    "tp.parse_archive(get_user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}