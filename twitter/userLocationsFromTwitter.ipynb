{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geonamescache\n",
    "gc = geonamescache.GeonamesCache()\n",
    "internat_cities = [c for c in gc.get_cities().values() if c['population'] >= 100000 and c['countrycode'] != 'US']\n",
    "import pycountry\n",
    "countries = [c.name.title() for c in pycountry.countries]\n",
    "planets = ['Mercury', 'Venus', 'Earth', 'Mars', 'Moon', 'Jupiter', 'Saturn', 'Uranus', 'Neptune', 'Pluto'] #Pluto is not a planet\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cit_file = \"data/uscities.csv\"\n",
    "cities = []\n",
    "with open(cit_file, \"r\") as f:\n",
    "    k = 0\n",
    "    for line in f:\n",
    "        if k == 0:\n",
    "            k=1\n",
    "            continue\n",
    "        \n",
    "        row = [x.replace('\\\"', '') for x in line.split(',')]\n",
    "        try:\n",
    "            temp = {\n",
    "                'name':row[0],\n",
    "                'state':row[2],\n",
    "                'longitude':float(row[8]),\n",
    "                'latitude':float(row[9]),\n",
    "                'population':int(round(float(row[10]))),\n",
    "                'density':float(row[11])\n",
    "            }\n",
    "            cities.append(temp)\n",
    "        except:\n",
    "            temp = {\n",
    "                'name':', '.join(row[0:2]),\n",
    "                'state':row[4],\n",
    "                'longitude':row[10],\n",
    "                'latitude':row[11],\n",
    "                'population':int(round(float(row[12]))),\n",
    "                'density':float(row[13])\n",
    "            }\n",
    "            cities.append(temp)\n",
    "city_names = {}\n",
    "for c in cities:\n",
    "    if c['name'] in city_names.keys():\n",
    "        city_names[c['name']].append(c)\n",
    "    else:\n",
    "        city_names[c['name']] = [c]\n",
    "for c in internat_cities:\n",
    "    if c['name'] in city_names.keys():\n",
    "        c['state'] = 'INTERNATIONAL'\n",
    "        city_names[c['name']].append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_name = \"data/stream/2015/04/07\"\n",
    "save_name = \"data/twitter_dump.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbr_to_states = {\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'DC': 'District of Columbia',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VI': 'Virgin Islands',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming'\n",
    "}\n",
    "\n",
    "state_to_abbr = {v.upper():k for k,v in abbr_to_states.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wash_dc = [c for c in city_names['Washington'] if c['state']=='DC']\n",
    "wash_dc = wash_dc[0]\n",
    "nyc = city_names['New York'][0]\n",
    "\n",
    "def match_country(st):\n",
    "    if st.lower() in ['us', 'usa', 'america', 'united states', 'united states of america', 'amerika', 'murica', \"'murica\"]:\n",
    "        return 'USA'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def match_state(st):\n",
    "    stat = st.upper()\n",
    "    if 'USA' in stat:\n",
    "        stat = stat.replace('USA', '').strip()\n",
    "    if 'AMERICA' in stat:\n",
    "        stat = stat.replace('AMERICA', '').strip()\n",
    "    if 'US' in stat:\n",
    "        stat = stat.replace('US', '').strip()\n",
    "    if stat in state_to_abbr.keys():\n",
    "        return state_to_abbr[stat]\n",
    "    elif stat not in state_to_abbr.values():\n",
    "        return None\n",
    "    return stat\n",
    "\n",
    "def match_city(cit, st = None):\n",
    "    city = cit.title()\n",
    "    if city == 'New York City' or cit == 'Nyc':\n",
    "        return nyc\n",
    "    if st is None:\n",
    "        if city in countries or city in planets:\n",
    "            return None\n",
    "        out = city_names.get(city, [])\n",
    "        if len(out) > 1:\n",
    "            temp = 0\n",
    "            for c in out:\n",
    "                if c['population']>temp:\n",
    "                    temp = c['population']\n",
    "                    oout = c\n",
    "            if oout['state'] != 'INTERNATIONAL':\n",
    "                return oout\n",
    "            else:\n",
    "                return None\n",
    "        elif len(out)==1:\n",
    "            return out[0]\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        #print(cit, st)\n",
    "        if st == 'DC':\n",
    "            return wash_dc\n",
    "        out = city_names.get(cit, None)\n",
    "        if out:\n",
    "            out = [c for c in out if c['state'] == st.upper()]\n",
    "            if out:\n",
    "                return out[0]\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "def match_string(st):\n",
    "    st = st.strip()\n",
    "    st = st.replace('.', '')\n",
    "    if st.lower() == 'la':\n",
    "        return match_string('Los Angeles, CA')\n",
    "    if st.lower() == 'sf':\n",
    "        return match_string('San Francisco, CA')\n",
    "    if st.lower() == 'nyc':\n",
    "        return nyc\n",
    "    if 'nova iorque' in st.lower():\n",
    "        return nyc\n",
    "    if 'washington' in st.lower() and 'dc' in st.lower().replace('.',''):\n",
    "        return wash_dc\n",
    "    if st.count(',') == 0:\n",
    "        try:\n",
    "            out = match_country(st)\n",
    "            if out:\n",
    "                return out\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            out = match_state(st)\n",
    "            if out:\n",
    "                return out\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            out = match_city(st)\n",
    "            if out:\n",
    "                return out\n",
    "        except:\n",
    "            pass\n",
    "        if st.count(' ') > 0:\n",
    "            temp = st.split(' ')\n",
    "            if len(temp) == 2:\n",
    "                return match_string(', '.join(temp))\n",
    "            else:\n",
    "                return match_string(' '.join(temp[0:-1]) + ', ' + temp[-1])\n",
    "        return None\n",
    "    elif st.count(',') == 1:\n",
    "        cit, st = st.split(',')\n",
    "        cit = cit.strip().title()\n",
    "        st = st.strip().upper()\n",
    "        if match_country(st):\n",
    "            if match_state(cit.upper()):\n",
    "                return match_state(cit.upper())\n",
    "            elif match_city(cit):\n",
    "                return match_city(cit)\n",
    "            else:\n",
    "                return 'USA'\n",
    "        elif match_state(st):\n",
    "            st = match_state(st)\n",
    "            if match_city(cit,st):\n",
    "                return match_city(cit,st)\n",
    "            else:\n",
    "                \"\"\"\n",
    "                This is where I am going to do google geocoding to get the city\n",
    "                \"\"\"\n",
    "                return None\n",
    "                url = gmaps_url + cit + ',' + st + key_str\n",
    "                response=requests.get(url)\n",
    "                if response.status_code < 400:\n",
    "                    results = response.json()['results']\n",
    "                    if results:\n",
    "                        results = results[0]\n",
    "                        addr_components = [x['long_name'].title() for x in results['address_components']]\n",
    "                        if cit in addr_components:\n",
    "                            out = {\n",
    "                                'state':st,\n",
    "                                'name':cit,\n",
    "                                'latitude':results['geometry']['location']['lat'],\n",
    "                                'longitude':results['geometry']['location']['lng']\n",
    "                            }\n",
    "                            return out\n",
    "                        else:\n",
    "                            return st\n",
    "                    else:\n",
    "                        return st\n",
    "                else:\n",
    "                    return st\n",
    "\n",
    "        else:\n",
    "            return None\n",
    "    elif st.count(',') == 2:\n",
    "        cit, st, ct = st.split(',')\n",
    "        if match_country(ct.strip()):\n",
    "            return match_string(','.join([cit,st]))\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_data(tweet):\n",
    "    if (not tweet) or (not tweet.get('user', None)) or (not tweet['user']['location']):\n",
    "        return None\n",
    "    loc = match_string(tweet['user']['location'])\n",
    "    if loc:\n",
    "        if type(loc)==dict:\n",
    "            out = [\n",
    "                tweet['user']['id_str'],\n",
    "                tweet['user']['friends_count'],\n",
    "                tweet['user']['followers_count'],\n",
    "                loc['state'],\n",
    "                loc['name'],\n",
    "                loc['latitude'],\n",
    "                loc['longitude'],\n",
    "                tweet['user']['created_at']\n",
    "            ]\n",
    "        else:\n",
    "            out = [\n",
    "                tweet['user']['id_str'],\n",
    "                tweet['user']['friends_count'],\n",
    "                tweet['user']['followers_count'],\n",
    "                loc,\n",
    "                None,\n",
    "                None,\n",
    "                None,\n",
    "                tweet['user']['created_at']\n",
    "            ]\n",
    "        return out\n",
    "    else:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twitterArchiveParser import twitterArchiveParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = twitterArchiveParser(archive_location=arc_name, save_location = save_name, num_threads = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Thread finished\n\nThread finished\n\nThread finished\n\nThread finished\n\nThread finished\n\nThread finished\n\nThread finished\n\n"
    }
   ],
   "source": [
    "tp.parse_archive(get_user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}